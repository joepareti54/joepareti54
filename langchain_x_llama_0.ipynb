{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcovZ+LycECT2sBNqtChVz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joepareti54/joepareti54/blob/main/langchain_x_llama_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install replicate\n",
        "#https://replicate.com/blog/run-llama-2-with-an-api#running-llama-2-with-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4x8d68qtKXJ",
        "outputId": "4e0e7927-de25-4f47-99c7-ecbfea3c7f83"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting replicate\n",
            "  Downloading replicate-0.25.1-py3-none-any.whl (39 kB)\n",
            "Collecting httpx<1,>=0.21.0 (from replicate)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (24.0)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.10/dist-packages (from replicate) (2.6.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (4.10.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.21.0->replicate)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.21.0->replicate)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (2.16.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.0)\n",
            "Installing collected packages: h11, httpcore, httpx, replicate\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 replicate-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwlPAy1wuxDO",
        "outputId": "dc653bcb-5e36-4e7c-ecb9-ea7d9f7af99c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error generating response: {\"title\":\"Invalid version or not permitted\",\"detail\":\"The specified version does not exist (or perhaps you don't have permission to use it?)\",\"status\":422}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import requests  # Use the requests library to make HTTP requests\n",
        "\n",
        "class LLM:\n",
        "    def __init__(self, model_name, replicate_api_token):\n",
        "        self.model_name = model_name\n",
        "        self.replicate_api_token = replicate_api_token\n",
        "\n",
        "    def generate(self, prompt):\n",
        "        # Using Replicate's API to generate a response based on the prompt\n",
        "        try:\n",
        "            headers = {\n",
        "                \"Authorization\": f\"Token {self.replicate_api_token}\",\n",
        "                \"Content-Type\": \"application/json\"\n",
        "            }\n",
        "            data = {\n",
        "                \"version\": self.model_name,  # Specify the model version (identifier for Llama 2 7B)\n",
        "                \"input\": {\n",
        "                    \"prompt\": prompt,\n",
        "                    \"max_tokens\": 100  # Adjust based on your needs\n",
        "                }\n",
        "            }\n",
        "            response = requests.post('https://api.replicate.com/v1/predictions', json=data, headers=headers)\n",
        "            if response.status_code == 200:\n",
        "                # Assuming the API response structure, adjust as necessary\n",
        "                return response.json()['output']\n",
        "            else:\n",
        "                return f\"Error generating response: {response.text}\"\n",
        "        except Exception as e:\n",
        "            return f\"Error generating response: {e}\"\n",
        "\n",
        "# Assuming you have these values set appropriately\n",
        "API_TOKEN = \"r8_PukHyR1PKKUzCJpyQdodF4ZWdqXVrCM0uBiLt\"\n",
        "MODEL_IDENTIFIER = \"meta/llama-2-7b\"\n",
        "MODEL_IDENTIFIER = \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\"\n",
        "MODEL_IDENTIFIER = \"meta/llama-2-70b-chat:2c1608e18606fad2812020dc541930f2d0495ce32eee50074220b87300bc16e1\"\n",
        "\n",
        "\n",
        "llm = LLM(model_name=MODEL_IDENTIFIER, replicate_api_token=API_TOKEN)\n",
        "\n",
        "# Example usage\n",
        "prompt = \"Please write a four line rhyming poem about spring.\"\n",
        "response = llm.generate(prompt)\n",
        "\n",
        "print(response)\n"
      ]
    }
  ]
}