{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import librosa\n",
    "path  =  '/home/joseph/ASRVerify'\n",
    "path_t=  '/home/joseph/ASRVerify'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4_W0lhaQlRzx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2021-08-09 16:08:17 optimizers:47] Apex was not found. Using the lamb optimizer will error out.\n",
      "[NeMo W 2021-08-09 16:08:17 nemo_logging:349] /home/joseph/anaconda3/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2021-08-09 16:08:24 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_text_dali.AudioToCharDALIDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "import nemo\n",
    "# NeMo's ASR collection - this collections contains complete ASR models and\n",
    "# building blocks (modules) for ASR\n",
    "import nemo.collections.asr as nemo_asr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_W8EbYktZE3"
   },
   "source": [
    "## Using an Out-of-the-Box Model\n",
    "\n",
    "NeMo's ASR collection comes with many building blocks and even complete models that we can use for training and evaluation. Moreover, several models come with pre-trained weights. Let's instantiate a complete QuartzNet15x5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KFZZpYult96G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-08-09 16:08:24 cloud:56] Found existing object /home/joseph/.cache/torch/NeMo/NeMo_1.2.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo.\n",
      "[NeMo I 2021-08-09 16:08:24 cloud:62] Re-using file from: /home/joseph/.cache/torch/NeMo/NeMo_1.2.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo\n",
      "[NeMo I 2021-08-09 16:08:24 common:676] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2021-08-09 16:08:26 features:252] PADDING: 16\n",
      "[NeMo I 2021-08-09 16:08:26 features:269] STFT using torch\n",
      "[NeMo I 2021-08-09 16:08:29 modelPT:438] Model EncDecCTCModel was successfully restored from /home/joseph/.cache/torch/NeMo/NeMo_1.2.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo.\n"
     ]
    }
   ],
   "source": [
    "# This line will download pre-trained QuartzNet15x5 model from NVIDIA's NGC cloud and instantiate it for you\n",
    "quartznet = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name=\"QuartzNet15x5Base-En\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PXVKBniMlRz5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'QuartzNet15x5', 'sample_rate': 16000, 'repeat': 1, 'dropout': 0.0, 'separable': True, 'labels': [' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\"], 'model': {'train_ds': {'manifest_filepath': '???', 'sample_rate': 16000, 'labels': [' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\"], 'batch_size': 32, 'trim_silence': True, 'max_duration': 16.7, 'shuffle': True, 'is_tarred': False, 'tarred_audio_filepaths': None, 'tarred_shard_strategy': 'scatter'}, 'validation_ds': {'manifest_filepath': '???', 'sample_rate': 16000, 'labels': [' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\"], 'batch_size': 32, 'shuffle': False}, 'preprocessor': {'_target_': 'nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor', 'normalize': 'per_feature', 'window_size': 0.02, 'sample_rate': 16000, 'window_stride': 0.01, 'window': 'hann', 'features': 64, 'n_fft': 512, 'frame_splicing': 1, 'dither': 1e-05, 'stft_conv': False}, 'spec_augment': {'_target_': 'nemo.collections.asr.modules.SpectrogramAugmentation', 'rect_freq': 50, 'rect_masks': 5, 'rect_time': 120}, 'encoder': {'_target_': 'nemo.collections.asr.modules.ConvASREncoder', 'feat_in': 64, 'activation': 'relu', 'conv_mask': True, 'jasper': [{'filters': 128, 'repeat': 1, 'kernel': [11], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True, 'separable': True, 'se': True, 'se_context_size': -1}, {'filters': 256, 'repeat': 1, 'kernel': [13], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True, 'separable': True, 'se': True, 'se_context_size': -1}, {'filters': 256, 'repeat': 1, 'kernel': [15], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True, 'separable': True, 'se': True, 'se_context_size': -1}, {'filters': 256, 'repeat': 1, 'kernel': [17], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True, 'separable': True, 'se': True, 'se_context_size': -1}, {'filters': 256, 'repeat': 1, 'kernel': [19], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': True, 'separable': True, 'se': True, 'se_context_size': -1}, {'filters': 256, 'repeat': 1, 'kernel': [21], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': False, 'separable': True, 'se': True, 'se_context_size': -1}, {'filters': 1024, 'repeat': 1, 'kernel': [1], 'stride': [1], 'dilation': [1], 'dropout': 0.0, 'residual': False, 'separable': True, 'se': True, 'se_context_size': -1}]}, 'decoder': {'_target_': 'nemo.collections.asr.modules.ConvASRDecoder', 'feat_in': 1024, 'num_classes': 28, 'vocabulary': [' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\"]}, 'optim': {'name': 'novograd', 'lr': 0.01, 'betas': [0.8, 0.5], 'weight_decay': 0.001, 'sched': {'name': 'CosineAnnealing', 'monitor': 'val_loss', 'reduce_on_plateau': False, 'warmup_steps': None, 'warmup_ratio': None, 'min_lr': 0.0, 'last_epoch': -1}}}, 'trainer': {'gpus': 0, 'max_epochs': 5, 'max_steps': None, 'num_nodes': 1, 'accelerator': 'ddp', 'accumulate_grad_batches': 1, 'checkpoint_callback': False, 'logger': False, 'log_every_n_steps': 1, 'val_check_interval': 1.0}, 'exp_manager': {'exp_dir': None, 'name': 'QuartzNet15x5', 'create_tensorboard_logger': True, 'create_checkpoint_callback': True}, 'hydra': {'run': {'dir': '.'}, 'job_logging': {'root': {'handlers': None}}}}\n"
     ]
    }
   ],
   "source": [
    "# --- Config Information ---#\n",
    "try:\n",
    "    from ruamel.yaml import YAML\n",
    "except ModuleNotFoundError:\n",
    "    from ruamel_yaml import YAML\n",
    "config_path = '/home/joseph/ASRVerify/config.yaml'\n",
    "\n",
    "yaml = YAML(typ='safe')\n",
    "with open(config_path) as f:\n",
    "    params = yaml.load(f)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = '/home/joseph/ASRVerify/'\n",
    "CHECKPOINT_DIR = OUT_DIR + 'CHECKPOINT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input checkpoint file  /home/joseph/ASRVerify/CHECKPOINT/train-20000-40000-valid-End-1000-100e.chk\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "list_of_files = glob.glob(CHECKPOINT_DIR +'*') # * means all if need specific format then *.csv\n",
    "CHECKPOINT_FILE_IN = max(list_of_files, key=os.path.getctime)\n",
    "#\n",
    "print('input checkpoint file ',CHECKPOINT_FILE_IN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEn2RyvgxxvO"
   },
   "source": [
    "Next, we instantiate and ASR model based on our ``config.yaml`` file from the previous section.\n",
    "Note that this is a stage during which we also tell the model where our training and validation manifests are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can i use this how?\n",
    "# https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/v1.0.0/asr/results.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2021-08-09 16:08:49 modelPT:138] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /media/joepareti54/Elements/x/finance-2020/AI/Listen_attend_spell/VCTK-Corpus/manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - a\n",
      "    - b\n",
      "    - c\n",
      "    - d\n",
      "    - e\n",
      "    - f\n",
      "    - g\n",
      "    - h\n",
      "    - i\n",
      "    - j\n",
      "    - k\n",
      "    - l\n",
      "    - m\n",
      "    - 'n'\n",
      "    - o\n",
      "    - p\n",
      "    - q\n",
      "    - r\n",
      "    - s\n",
      "    - t\n",
      "    - u\n",
      "    - v\n",
      "    - w\n",
      "    - x\n",
      "    - 'y'\n",
      "    - z\n",
      "    - ''''\n",
      "    batch_size: 32\n",
      "    trim_silence: true\n",
      "    max_duration: 16.7\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    \n",
      "[NeMo W 2021-08-09 16:08:49 modelPT:145] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /media/joepareti54/Elements/x/finance-2020/AI/Listen_attend_spell/VCTK-Corpus/t-manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - a\n",
      "    - b\n",
      "    - c\n",
      "    - d\n",
      "    - e\n",
      "    - f\n",
      "    - g\n",
      "    - h\n",
      "    - i\n",
      "    - j\n",
      "    - k\n",
      "    - l\n",
      "    - m\n",
      "    - 'n'\n",
      "    - o\n",
      "    - p\n",
      "    - q\n",
      "    - r\n",
      "    - s\n",
      "    - t\n",
      "    - u\n",
      "    - v\n",
      "    - w\n",
      "    - x\n",
      "    - 'y'\n",
      "    - z\n",
      "    - ''''\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-08-09 16:08:49 features:252] PADDING: 16\n",
      "[NeMo I 2021-08-09 16:08:49 features:269] STFT using torch\n",
      "[NeMo I 2021-08-09 16:08:49 modelPT:438] Model EncDecCTCModel was successfully restored from /home/joseph/ASRVerify/CHECKPOINT/train-20000-40000-valid-End-1000-100e.chk.\n"
     ]
    }
   ],
   "source": [
    "MODEL = nemo_asr.models.EncDecCTCModel.restore_from(CHECKPOINT_FILE_IN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3FT0klSV268p"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a10e9cb76b4fb5b0236d8b309af376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2021-08-09 16:08:58 patch_utils:49] torch.stft() signature has been updated for PyTorch 1.7+\n",
      "    Please update PyTorch to remain compatible with later versions of NeMo.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eople leok but noone everfins at', 'y hard work is the ncer', ' have wone to buy wone fo the naionial galleory ', 'owever endee desaved to win this came']\n"
     ]
    }
   ],
   "source": [
    "print(MODEL.transcribe(paths2audio_files=[path+'/p247_010.wav', path+'/p279_217.wav', path+'/p279_218.wav', path+'/p279_219.wav'],\n",
    "                                                    \n",
    "                                 batch_size=4))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "01_ASR_with_NeMo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
